<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-03-12T03:28:20+05:30</updated><id>http://localhost:4000/</id><title type="html">Blog</title><subtitle>Blog about Deep Learning</subtitle><author><name>Sarthak Anand</name><email>isarth@me.com</email></author><entry><title type="html">Extractive Text Summary using TextRank</title><link href="http://localhost:4000/hello/" rel="alternate" type="text/html" title="Extractive Text Summary using TextRank " /><published>2018-12-09T00:00:00+05:30</published><updated>2018-12-09T00:00:00+05:30</updated><id>http://localhost:4000/hello</id><content type="html" xml:base="http://localhost:4000/hello/">&lt;p&gt;For someone familiar with NLP and Deep learning, the Seq2Seq models come first in mind when we talk about summarization. But the main issue with it is that it requires a significant amount of data and resources for training such networks. In this post, I’ll cover TextRank which doesn’t require any training at all.&lt;/p&gt;

&lt;h4 id=&quot;goals&quot;&gt;Goals&lt;/h4&gt;
&lt;p&gt;The main purpose of this blog post is to provide an understanding of TextRank, which very intuitive way of summarizing the text.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;TextRank is a quite an old technique, it was originally published in 2004 but it still popular extractive summarization technique. It very easy to understand and does not require any training, and therefore commonly used as a baseline. In order to understand how text-rank works the sentences, I recommend going through my post on &lt;a href=&quot;https://isarth.github.io/pagerank/&quot;&gt;Page-Rank&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Before going through TextRank, let us first understand, what are the ways we can summarize a text. Mainly there are two ways:&lt;/p&gt;
&lt;h3 id=&quot;abstractive-and-extractive-summarization&quot;&gt;Abstractive and Extractive summarization&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/textrank/fig1.JPEG&quot; /&gt;

&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Extractive&lt;/strong&gt;  : It is similar to highlighting, We pick relevant sentences from the document, that make up the summary. Techniques used for the extractive summarization are graph based methods like TextRank,LexRank.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Abstractive&lt;/strong&gt; : It is similar to reading the whole document and then making notes in our own words, that make up the summary. Techniques used for the abstractive summarization is the popular Seq2Seq LSTM networks or attention based models.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;text-rank&quot;&gt;Text Rank&lt;/h3&gt;
&lt;p&gt;Quoting from the paper &lt;em&gt;“TextRank – is a graph-based unsupervised method for keyword and sentence
extraction”.&lt;/em&gt; Because it is unsupervised ranking method, it does require any training and supervised data.&lt;br /&gt;&lt;br /&gt;
 Focusing only on the summarization or sentence extraction, basic intuition behind text-rank is that, we want to extract sentences that can cover a major part of the text or which are a lot similar to other sentences. And in order to extract them, we somehow need to rank them based on this similarity criteria, this is where Page-rank comes into the picture. It is used for ranking the sentences based on their similarity.&lt;/p&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/textrank/fig2.JPEG&quot; /&gt;

&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We construct a graph of sentences where each node is a represents a sentence and all the sentences are connected to each other by (directed on an undirected) edges.&lt;/li&gt;
  &lt;li&gt;The weight of the edge is equal to the similarity between the two sentences. And then we apply Page rank over the graph to rank the sentences.&lt;/li&gt;
  &lt;li&gt;Finally we select K top sentences that represent our summary.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Basically this is it. Nothing complex and still provides decent results.&lt;/p&gt;

&lt;h3 id=&quot;sentence-similarity&quot;&gt;Sentence similarity&lt;/h3&gt;

&lt;p&gt;The weight of the edge is a value representing the similarity between the two sentences. Originally in the paper, it was calculated using a number of common words present in the sentence. In order to repress the selection of long sentences, the value is divided by the lengths of the sentences. &lt;br /&gt;&lt;br /&gt;
Finally, given two sentences Si and Sj  , with a sentence being represented by the set of Ni words that appear in the sentence: Si = w1,w2,w3…wn the similarity of Si and Sj is defined as&lt;/p&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;

&lt;p&gt;\begin{equation}
 Similarity(S_i,S_j)=\dfrac{| {w_k|w_k \epsilon{S_i} \space \&amp;amp; \space w_k \epsilon{S_j}| } }{log(|S_i|)+log(|S_j|)} 
\end{equation}&lt;/p&gt;

&lt;h3 id=&quot;implementation-of-text-rank&quot;&gt;Implementation of Text rank&lt;/h3&gt;

&lt;p&gt;In order to explain it I made a jupyter noteboook &lt;a href=&quot;https://github.com/isarth/text_rank/blob/master/exp/text_rank.ipynb&quot;&gt;Link&lt;/a&gt; or you can use sumy a python library that has already implemented it !!&lt;/p&gt;</content><author><name>Sarthak Anand</name><email>isarth@me.com</email></author><summary type="html">For someone familiar with NLP and Deep learning, the Seq2Seq models come first in mind when we talk about summarization. But the main issue with it is that it requires a significant amount of data and resources for training such networks. In this post, I’ll cover TextRank which doesn’t require any training at all.</summary></entry><entry><title type="html">Understanding PageRank</title><link href="http://localhost:4000/pagerank/" rel="alternate" type="text/html" title="Understanding PageRank" /><published>2018-10-15T00:00:00+05:30</published><updated>2018-10-15T00:00:00+05:30</updated><id>http://localhost:4000/pagerank</id><content type="html" xml:base="http://localhost:4000/pagerank/">&lt;p&gt;In simple terms, PageRank is an intuitive way of ranking web pages, which formed the basis for Google’s web indexing algorithm during its early phase. In this article, you’ll learn about the intuition behind page rank and implementing page rank in python. The article is divided into the following sections:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basic Idea behind Page Rank&lt;/li&gt;
  &lt;li&gt;Understanding the Pank Rank algorithm&lt;/li&gt;
  &lt;li&gt;Implementing Page Rank from scratch&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;basic-idea-behind-page-rank&quot;&gt;Basic Idea behind Page Rank&lt;/h2&gt;
&lt;p&gt;The intuition behind the Page-Rank is based on the idea that popularity of a webpage is determined not only by the number of incoming links but also by the kind of incomings links. Citations from highly ranked pages contribute more than lower ranked web pages, for example if your website in linked by forbes website it will affect your ranking more than compared to a random website.&lt;br /&gt; 
&lt;br /&gt;
Taking it further let’s take an example for calculation the PR of a web page A cited by web page B shown in Fig. 1:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/ex.png&quot; /&gt;
&lt;figcaption align=&quot;center&quot;&gt;Fig.1 Example of web graph.&lt;/figcaption&gt;
&lt;/p&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;

&lt;p&gt;\begin{equation}
 PR(A)=(1-d)* (1/N)+ d* P(B,A)*PR(B) 
\end{equation}&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt;
 PR(A): PR of A&lt;br /&gt;
 PR(B): PR of B&lt;br /&gt;
 P(B,A): Probability going from B to A (here it is equal to one)&lt;br /&gt;
 N: Total number of webpages(in our case 2).&lt;br /&gt;
 d: is known as damping factor, to add some randomness to the equation. 
&lt;/p&gt;
&lt;p&gt;Simultaneously PR of B is calculated. This process continues until it PR does not change beyond some value.&lt;/p&gt;

&lt;h2 id=&quot;page-rank-algorithm&quot;&gt;Page Rank Algorithm&lt;/h2&gt;
&lt;p&gt;Taking it further we and to have a better understanding of how page rank works, we consider a graph (shown by fig 2) of web pages having links shown by the arrow. &lt;br /&gt;Note that, if there are web pages with no out link then they do not contribute to the page ranking (they are usually referred to as dangling pages).&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/graph.png&quot; /&gt;
&lt;figcaption align=&quot;center&quot;&gt;Fig.2&lt;/figcaption&gt;
&lt;/p&gt;
&lt;p&gt;Our aim in now to figure of the PR of individual web pages. Inorder to do so, we need to perform the following steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Find the probabilities of going from one web page to another (respresented using probability transition matrix)&lt;/li&gt;
  &lt;li&gt;Apply the page rank algorithm our the web page until it converges.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-1&quot;&gt;STEP 1&lt;/h3&gt;
&lt;p&gt;Initially, page rank of all the web pages is taken as 1. The weight of the edge is the probability of going from a web page X to Y ( the web page A has 2 out links, therefore, the probability to visit each web page is 1/2 ). After expressing the web graph in terms of probabilities the web graph looks something like:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/graph_prob.png&quot; /&gt;
&lt;figcaption align=&quot;center&quot;&gt;Fig.3&lt;/figcaption&gt;
&lt;/p&gt;
&lt;p&gt;Probability transition matrix is represented as:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/mat.JPEG&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-2&quot;&gt;STEP 2&lt;/h3&gt;
&lt;p&gt;The page rank of each web page is determined by applying the PageRank equation. This process is repeated until the algorithm converges i.e. the values of page rank do not change beyond a small value ( know as epsilon usually fixed as 1e-4 ). The damping factor (d) introduced is to add some randomness over the web graph i.e. d is a probability that a user will move to the linked web page and 1-d is the probability of choosing a random web page, it is usually taken as 0.85.&lt;/p&gt;
&lt;h4 id=&quot;iteration-1&quot;&gt;Iteration 1:&lt;/h4&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/formula.JPEG&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;PR(C)=(.15)*(1/4)+ .85*(.5*1 + 1*1 + 1*1) = 2.16&lt;/script&gt;
&lt;br /&gt;
&lt;br /&gt;
The PR(C) can also be calculated by matrix dot product.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/pr_c.JPEG&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;Similarly, extending this for all the web pages we end up with the equation:  &lt;br /&gt;  ( * represents matrix multiplication)&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/images/Page_rank/eq.JPEG&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;\begin{equation}
 PR=(1-d)(1/N)+ d* (C^T*PR) 
\end{equation}&lt;/p&gt;

&lt;p&gt;Where matrix C represents the probability transition ( C[i][j] = probability of the user transitioning from page i to page j).
The C matrix of our example can be expressed as the matrix represented above. Also, the initial page ranks are as assigned 1 for all the web pages. The PRs of web pages are calculated until the PRs converge to a certain value.&lt;/p&gt;

&lt;h2 id=&quot;implementing-page-rank&quot;&gt;Implementing Page Rank&lt;/h2&gt;
&lt;p&gt;Page Rank implementation in python:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pagerank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;P_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P_&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pagerank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#result&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#p=[1.16, 0.644, 1.19, 0.15]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Final ranking of our example are C &amp;gt; A &amp;gt; B &amp;gt; D !&lt;/p&gt;

&lt;p&gt;Notice: page rank of A is high even when it has only one incoming link.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm&quot;&gt;Page Rank Explained&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/PageRank#Iterative&quot;&gt;Wikipedia Pagerank&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sarthak Anand</name><email>isarth@me.com</email></author><summary type="html">Indexing the web pages</summary></entry></feed>