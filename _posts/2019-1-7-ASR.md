---
layout: single
title: Automatic Speech Recognition(ASR) 
excerpt: "Basic Overview of Deep Learning Approach"
header:
  overlay_color: "#333"
share: false
toc: true

#date:   2019-1-7 16:16:01 -0600


---
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

The whole pipeline to convert speech to text is known as Automatic Speech Recognition (ASR), which formes the basis for Google's voice assistant sysytems. In this article, you'll learn about the intuition behind the ASR. The article is divided into the following sections:

+ The Big Picture 
+ Understanding Individual elements of ASR pipeline
+ Handling Out of Vocabulary Words (OOV) words  

Speech Recognition is a sequence labelling task, compoared to image labelling where samples are independent. 
Word error rate (WER), Character error rate (CER) and Sentence error rate (SER) are some of the metrices to Measure the performance of an ASR system.  

__WER__: It's computed using "String edit distance" or "Levenstein distance." It is
<!-- \\[WER = \frac{N<sub>sub</sub> + N<sub>ins</sub> + N<sub>del</sub>}{N<sub>ref</sub>}\\]. Where,   -->

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
\begin{equation}
 WER = \dfrac{N_(s) + N_i + N_}{N_r} 
\end{equation}

* N<sub>s</sub> = No. of substitutions, 
* N<sub>i</sub> = No. of insertions,
* N<sub>d</sub> = No. of deletions,
* N<sub>r</sub> = Words in the reference Transcription.  

i.e. the no of substitutions, insertions and deletions of __WORDS__ needed to get from the reference to hypothesis (ASR system best guess of the transcript).  

__CER__: Everythinng is sameexcept instead of WRODS it considers __CHARACTERS__ for all the calcualtions in the above formula.  

__SER__: It's very simple to calculate. according tothe SER defination, even if a single word in a sentence is incorrect it wil label it as incorrect hypothesis. SER is used as _proportion of incorect sentences to total number of sentences_


## The Big Picture
ASR Pipeline contains mainly 2 main components: Acoustic Model and a Language Model. The acoustic model is responsible for the acoustic representation and the language models come into the picture to make sense out of the predicted text.  
Language model also plays an importatn role when there is ambguity in the predictted text. for example, I _----_ you, if you have to choose between _NO_ and _KNOW_ which one whould you choose?
Ofcourse the second one, but why ? I would say, you have language understanding as one of your cognitive skills,that's how you  did it.  <br /> 
<br />
let's look at a diagram of the whole pipeline, as shown in Fig. 1:
<p align='center'>
<img src="/assets/images/asr/asr_pipeline.png">
<figcaption align='center'>Fig.1 ASR Pipeline.</figcaption>
</p>

The fundamental equation of speech is  \\(P(w/o)\\). For a given observations O=[o<sub>1</sub>,o<sub>2</sub>,.....,o<sub>n</sub>]

## Understanding Individual elements of ASR pipeline 
### Audio
Input is a RAW Audio signal/waveform, which is just the pressure waves recorded/stored digitally at a certain interval of time, or at a certain frequency. 
### Spectrogram 
It's a better representation of an Audio signal, to fed to a Neural Network. There is a saying in Machine learning communty: __Good Features make problems TRIVIAL__.
### Acoustic Model 
Acoustic models calculates/determines the probabiltiy of output(Y) conditioned on an input(X). The input is either Raw audio or spectrogram and the output is the predicted transcription.For each input Acoustic model ouputs probability of a set of pre-defined characters i.e. P(Y/X) 
### Connectionist temporal classification (CTC) 
ctc is a scoring/loss function to calculate the loss of an continous ouput with any Alignment information given. It takes into account all the possible alignments possible for a given output sentence using a Heuristic approach.
### Decoder :
Decoder plays an important role in the ASR pipeline. It helps in getting a word error rate (WER) from 30-40 to under 15 or in some domain specific cases upto under 10 percent (%). The decoding process is of two types:
+ Without the Language model (LM)
+ With the Character level Language model (CLM)



## Handling OOV words
There are Two ways to handle out of vocabulary(OOV) words:
+ Use only the Acoustic model output without any Language Model (LM) and.
+ Use of Character level Language Model.

## References

+ [My paper](https://drive.google.com/open?id=18j58woXz5WUgkHaOO3b7byRWck5Oyzg7)

+ [Deepspeech1 paper](https://arxiv.org/pdf/1412.5567.pdf)

+ [Deepspeech2 paper](https://arxiv.org/pdf/1512.02595.pdf)

+ [CTC paper](https://www.cs.toronto.edu/~graves/icml_2006.pdf)

+ [Spectrogram](https://en.wikipedia.org/wiki/Spectrogram)

If I have left someone, please let me know. I willadd the same to the refrence.

## My paper
<iframe src="/assets/images/asr/ASR_BigMM.pdf" width="700" height="800">