---
layout: single
title: Automatic Speech Recognition(ASR) 
excerpt: "Basic Overview of Deep Learning Approach"
header:
  overlay_color: "#333"
share: false
toc: true

#date:   2019-1-7 16:16:01 -0600


---
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

The whole pipeline to convert speech to text is known as Automatic Speech Recognition (ASR), which formes the basis for Google's voice assistant sysytems. Let's dive deep into, how to build a basic one. It's easy....blink..blink..  

Speech Recognition is a sequence labelling task, compared to image labelling where samples are independent. The fundamental equation of speech is  \\(P(w/o)\\) i.e. for given observations O = [o<sub>1</sub>,o<sub>2</sub>,.....,o<sub>n</sub>], we seek the most likley word sequence W = [w<sub>1</sub>,w<sub>2</sub>,.....,w<sub>n</sub>] \\[W = argmax (P(w / o)\\].

Like so many other tasks, [Bayes theorem ](https://en.wikipedia.org/wiki/Bayes%27_theorem) comes to our rescue. According to bayes theorem, \\(P(\frac{w}{o})\\) can be written as: \\[P(\frac{w}{o}) = \frac{P(\frac{o}{w}) * p(w)}{P(O)},\\]
\\(P(O)\\) is a marginalizing term or a constant for a particular given data. Therfore, \\[P(\frac{w}{o}) \\approx  P(\frac{o}{w}) * p(w).\\]  

\\(P(o / w) \\): It means, given the observed word sequence w, the one PDF or PMF \\(f(x / \\theta \\) among all the PDF's that are most likely to have produced the data.
<br />
\\(P(w)\\): It means, what is the probability of existing a particular word sequence. for example, the probability of a word sequence __ I know of __ is far greater than __ I no of __ is a language model constant for each word and can be calculated using a N-gram or Neural Language model.  
Popular N-gram language model toolkits are [KenLm](https://github.com/kpu/kenlm) and [SRILM](http://www.speech.sri.com/projects/srilm/).  

Word error rate (WER), Character error rate (CER) and Sentence error rate (SER) are some of the metrices to Measure the performance of an ASR system.  

__WER__: It's computed using "String edit distance" or "Levenstein distance." It is,
<!-- \\[WER = \frac{N<sub>sub</sub> + N<sub>ins</sub> + N<sub>del</sub>}{N<sub>ref</sub>}\\]. Where,   -->

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
\begin{equation}
 WER = \dfrac{N_s + N_i + N_d}{N_r} 
\end{equation}

* N<sub>s</sub> = No. of substitutions, 
* N<sub>i</sub> = No. of insertions,
* N<sub>d</sub> = No. of deletions,
* N<sub>r</sub> = Words in the reference Transcription.  

i.e. the no of substitutions, insertions and deletions of __WORDS__ needed to get from the reference to hypothesis (ASR system best guess of the transcript).  

__CER__: Everythinng is same, except instead of WORDS it considers __CHARACTERS__ for all the calcualtions in the above formula.  

__SER__: It's very simple to calculate. according tothe SER defination, even if a single word in a sentence is incorrect it wil label it as incorrect hypothesis. SER is used as _proportion of incorect sentences to total number of sentences_.  


In this article, you'll learn about the intuition behind the ASR. The article is divided into the following sections:

+ The Big Picture 
+ Understanding Individual elements of ASR pipeline
+ Handling Out of Vocabulary Words (OOV) words  

## ASR Pipeline
ASR Pipeline contains mainly 2 main components: Acoustic Model and a Language Model. The acoustic model is responsible for the acoustic representation and the language models come into the picture to make sense out of the predicted text.  
Language model also plays an importatn role when there is ambguity in the predictted text. for example, I _----_ you, if you have to choose between _NO_ and _KNOW_ which one whould you choose?
Ofcourse the second one, but why ? I would say, you have language understanding as one of your cognitive skills,that's how you  did it.  <br /> 
<br />
let's look at a diagram of the whole pipeline, as shown in Fig. 1:
<p align='center'>
<img src="/assets/images/asr/asr_pipeline.png">
<figcaption align='center'>Fig.1 ASR Pipeline.</figcaption>
</p>


## Understanding Individual elements of ASR pipeline 
### Audio
Input is a __raw__ Audio signal/waveform, which is just the pressure waves recorded/stored digitally at a certain interval of time, also called a sampling rate/frequency as can be seen in  Fig. 2.  
_Just for the information, humans can hear sounds at frequencies from about 20 Hz to 20,000 Hz, though we hear sounds best from 1,000 Hz to 5,000 Hz, where human speech is centered._
<p align='center'>
<img src="/assets/images/asr/audio.jpg">
<figcaption align='center'>Fig.2 Audio.</figcaption>
</p>
To store an audio digitally, we sample it at some predefined sampling rate and a certain bit depth (8 or 16). The right fig shows a digital signal and left fig shows an analog signal.

### Spectrogram 
It's a better representation of an Audio signal to fed a Neural Network. It combines both time and frequency information. There is a saying in Machine learning communty: __Good Features make problems TRIVIAL__.
### Acoustic Model 
Acoustic models calculates/determines the Likelihood of output(Y) conditioned on an input(X). The input is either Raw audio or spectrogram and the output is the predicted transcription.For each input Acoustic model ouputs probability of a set of pre-defined characters i.e. \\(L(Y/X)\\)
### Connectionist temporal classification (CTC) 
ctc is a scoring/loss function to calculate the loss of an continous ouput with any Alignment information given. It takes into account all the possible alignments possible for a given output sentence using a Heuristic approach.
### Decoder :
Decoder plays an important role in the ASR pipeline. It helps in getting a word error rate (WER) from 30-40 to under 15 or in some domain specific cases upto under 10 percent (%). The decoding process is of two types:
+ Without the Language model (LM)
+ With the Character level Language model (CLM)



## Handling OOV words
There are Two ways to handle out of vocabulary(OOV) words:
+ Use only the Acoustic model output without any Language Model (LM) and.
+ Use of Character level Language Model.

## References

+ [My paper](https://drive.google.com/open?id=18j58woXz5WUgkHaOO3b7byRWck5Oyzg7)

+ [Deepspeech1 paper](https://arxiv.org/pdf/1412.5567.pdf)

+ [Deepspeech2 paper](https://arxiv.org/pdf/1512.02595.pdf)

+ [CTC paper](https://www.cs.toronto.edu/~graves/icml_2006.pdf)

+ [Spectrogram](https://en.wikipedia.org/wiki/Spectrogram)

If I have left someone, please let me know. I willadd the same to the refrence.

## My paper
<iframe src="/assets/images/asr/ASR_BigMM.pdf" width="700" height="800">