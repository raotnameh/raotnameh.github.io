---
layout: single
title: Named Entity Recognition(NER) 
excerpt: "Generating NER tags directly through the Speech"
header:
  overlay_color: "#333"
share: false
toc: true

#date:   2019-10-12 16:16:01 -0600


---

## Introduction

 Named entity recognition (NER) is among SLU tasks that usually extract semantic information from textual documents.  NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propagation is the prinicipal one ) and it is known that more integrated approaches outperform se- quential ones, when they can be applied. 

 Named entities are sequences of words that bring basic predefined semantic information that usually refers to locations, persons, organization that can be denoted by proper nouns or that are unique in the real world, and they usually include numeric and temporal values. Named entities often constitute the first semantic bricks to extract in order to construct a structured semantic representation of a document content.

 Apart from all these the output of Automatic Speech Recognition (ASR) model does not have Puncuations or Captitalization of Words and the classical NER models (Stanford, Spacy NER to name few) heavily depends on these features to deduce the NER tags.

 The output of ASR system looks like (MY NAME IS HEMANT, I LIVE IN NEW DELHI). HEMANT AND NEW DELHI are NER tags.

 ASR errors have a negative impact on the NER performances, introducing noise within the text to be processed[1]. Rule-based NER systems are usually built to process written language and are not robust to ASR errors. Machine learning based systems do not have good performance when they are trained on perfect transcriptions and deployed to process ASR ones, even if that can be partially compensated by simulating ASR errors in textual training data. Additionally, ASR systems are generally tuned in order to get the lowest word error rate (WER) on a validation corpus, but this metric is not optimal to the NER task. For instance, this metric does not distinguish between errors on verbs or proper nouns while such errors do not have the same impact for NER. To compensate this problem, some dedicated metrics to tune ASR systems for better NER performances have been proposed.

## Pipeline
### Old approach
It is a two step process i.e. First getting the transcriptions out of an ASR model and then applying a state of the art NER tagger on the output.
### New approach
In this approach the NER tags are genrated directly through speech in one step i.e. NER tags are genreated on the go at the same time of transcption.
### Comaprison
The two step approach has a main disadvantage over the other i.e. 


## References

+ [End-to-end named entity extraction from speech](https://arxiv.org/pdf/1805.12045.pdf)

+ 1 : [Named Entity Recognition in Speech Transcripts following an Extended
Taxonomy](https://www.isca-speech.org/archive/slam_2013/papers/slm3_061.pdf)

+ 2 : [Simulating ASR errors for training SLU systems](https://www.aclweb.org/anthology/L18-1499.pdf)

+ 3 : [Investigating the Effect of ASR tuning on Named Entity Recognition](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/1482.PDF)

If I have left someone, please let me know. I willadd the same to the refrence.
